
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>cpac Python Package &#8212; C-PAC 1.6.2 Beta documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="genindex" />
    <link rel="search" title="Search" href="search" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index">C-PAC 1.6.2 Beta documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="cpac-python-package">
<h1>cpac Python Package<a class="headerlink" href="#cpac-python-package" title="Permalink to this headline">¶</a></h1>
<p>A <a class="reference external" href="https://pypi.org/project/cpac-py/">C-PAC Python package</a> is available so that you can easily run analyses without needing interact with the container platform that allows you to run C-PAC without installing all of the underlying software.</p>
<p>Currently the C-PAC Python package supports Singularity (version ≥ 2.5 ≤ 3.0) and Docker.</p>
<p>The C-PAC Python package requires Python 3.6 or greater. To get the C-PAC Python package, simply</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install cpac-py</span>
</pre></div>
</div>
<p>As a quick example, in order to run C-PAC in participant mode, for one participant, using a BIDS dataset stored on your machine or server, and using the container image’s default pipeline configuration:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/local_bids_data /Users/You/some_folder_for_outputs participant</span>
</pre></div>
</div>
<p>By default, the C-PAC Python package will try Docker first and fall back to Singularity if Docker fails. If both fail, an exception is raised.</p>
<p>You can specify a platform with the <code class="docutils literal notranslate"><span class="pre">--platform</span> <span class="pre">docker</span></code> or <code class="docutils literal notranslate"><span class="pre">--platform</span> <span class="pre">singularity</span></code>. If you specify a platform without specifying an image, these are the defaults, using the first successfully found image:</p>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ cpac --help
usage: cpac [-h] [--platform {docker,singularity}] [--image IMAGE] [--tag TAG]
            [--version] [-v] [-vv] [--working_dir PATH] [--temp_dir PATH]
            [--output_dir PATH] [-o OPT [OPT ...]]
            {run,utils} ...

cpac: a Python package that simplifies using C-PAC &lt;http://fcp-indi.github.io&gt;
containerized images. If no platform nor image is specified, cpac will try
Docker first, then try Singularity if Docker fails.

positional arguments:
  {run,utils}

optional arguments:
  -h, --help            show this help message and exit
  --platform {docker,singularity}
  --image IMAGE         path to Singularity image file OR name of Docker image
                        (eg, &quot;fcpindi/c-pac&quot;). Will attempt to pull from
                        Singularity Hub or Docker Hub if not provided.
  --tag TAG             tag of the Docker image to use (eg, &quot;latest&quot; or
                        &quot;nightly&quot;).
  --version             show program&#39;s version number and exit
  -v, --verbose         set loglevel to INFO
  -vv, --very-verbose   set loglevel to DEBUG
  --working_dir PATH    working directory
  --temp_dir PATH       directory for temporary files
  --output_dir PATH     directory where output files should be stored
  -o OPT [OPT ...], --container_options OPT [OPT ...]
                        parameters and flags to pass through to Docker or
                        Singularity
</pre></div>
</div>
<div class="section" id="platform-docker">
<h3>–platform docker<a class="headerlink" href="#platform-docker" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Look for <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac:latest</span></code> locally.</li>
<li>Pull <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac:latest</span></code> from Docker Hub.</li>
</ul>
</div>
<div class="section" id="platform-singularity">
<h3>–platform singularity<a class="headerlink" href="#platform-singularity" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Look in the present working directory for any Singularity images. If more than one is found, use the most recently modified.</li>
<li>Pull <code class="docutils literal notranslate"><span class="pre">FCP-INDI/C-PAC</span></code> from Singularity Hub.</li>
<li>Pull <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac:latest</span></code> from Docker Hub and convert to a Singularity image.</li>
</ul>
<p>You can also specify a container image with an <code class="docutils literal notranslate"><span class="pre">--image</span></code> argument, passing an image name (e.g., <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac</span></code>) for a Docker image or a filepath (e.g. <code class="docutils literal notranslate"><span class="pre">~/singularity_images/C-PAC.sif</span></code>) for a Singularity image. You can also specify a <code class="docutils literal notranslate"><span class="pre">--tag</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">latest</span></code> or <code class="docutils literal notranslate"><span class="pre">nightly</span></code>).</p>
<p>You can also provide a link to an AWS S3 bucket containing a BIDS directory as the data source:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run s3://fcp-indi/data/Projects/ADHD200/RawDataBIDS /Users/You/some_folder_for_outputs participant</span>
</pre></div>
</div>
<p>In addition to the default pipeline, C-PAC comes packaged with a growing library of pre-configured pipelines that are ready to use. To run C-PAC with one of the pre-packaged pre-configured pipelines, simply invoke the <code class="docutils literal notranslate"><span class="pre">--preconfig</span></code> flag, shown below. See the full selection of pre-configured pipelines <a class="reference internal" href="preconfig"><span class="doc">here</span></a>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/local_bids_data /Users/You/some_folder_for_outputs --preconfig anat-only</span>
</pre></div>
</div>
<p>To run C-PAC with a pipeline configuration file other than one of the pre-configured pipelines, assuming the configuration file is in the <code class="docutils literal notranslate"><span class="pre">/Users/You/Documents</span></code> directory:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/local_bids_data /Users/You/some_folder_for_outputs participant --pipeline_file /Users/You/Documents/pipeline_config.yml</span>
</pre></div>
</div>
<p>Finally, to run C-PAC with a specific data configuration file (instead of providing a BIDS data directory):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/any_directory /Users/You/some_folder_for_outputs participant --data_config_file /Users/You/Documents/data_config.yml</span>
</pre></div>
</div>
<p>Note: we are still providing the postionally-required <code class="docutils literal notranslate"><span class="pre">bids_dir</span></code> input parameter. However C-PAC will not look for data in this directory when you provide a data configuration YAML with the <code class="docutils literal notranslate"><span class="pre">--data_config_file</span></code> flag. Providing <code class="docutils literal notranslate"><span class="pre">.</span></code> or <code class="docutils literal notranslate"><span class="pre">$PWD</span></code> will simply pass the present working directory. In addition, if the dataset in your data configuration file is not in BIDS format, just make sure to add the <code class="docutils literal notranslate"><span class="pre">--skip_bids_validator</span></code> flag at the end of your command to bypass the BIDS validation process.</p>
<p>The full list of parameters and options that can be passed to C-PAC are shown below:</p>
</div>
</div>
<div class="section" id="usage-cpac-run">
<h2>Usage: cpac run<a class="headerlink" href="#usage-cpac-run" title="Permalink to this headline">¶</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ cpac run --help
...
usage: run.py [-h] [--pipeline_file PIPELINE_FILE] [--group_file GROUP_FILE]
              [--data_config_file DATA_CONFIG_FILE] [--preconfig PRECONFIG]
              [--pipeline_override PIPELINE_OVERRIDE]
              [--aws_input_creds AWS_INPUT_CREDS]
              [--aws_output_creds AWS_OUTPUT_CREDS] [--n_cpus N_CPUS]
              [--mem_mb MEM_MB] [--mem_gb MEM_GB]
              [--save_working_dir [SAVE_WORKING_DIR]] [--disable_file_logging]
              [--participant_label PARTICIPANT_LABEL [PARTICIPANT_LABEL ...]]
              [--participant_ndx PARTICIPANT_NDX] [-v]
              [--bids_validator_config BIDS_VALIDATOR_CONFIG]
              [--skip_bids_validator] [--anat_only] [--tracking_opt-out]
              [--monitoring]
              bids_dir output_dir {participant,group,test_config,gui,cli}

C-PAC Pipeline Runner

positional arguments:
  bids_dir              The directory with the input dataset formatted
                        according to the BIDS standard. Use the format
                        s3://bucket/path/to/bidsdir to read data directly from
                        an S3 bucket. This may require AWS S3 credentials
                        specified via the --aws_input_creds option.
  output_dir            The directory where the output files should be stored.
                        If you are running group level analysis this folder
                        should be prepopulated with the results of the
                        participant level analysis. Use the format
                        s3://bucket/path/to/bidsdir to write data directly to
                        an S3 bucket. This may require AWS S3 credentials
                        specified via the --aws_output_creds option.
  {participant,group,test_config,gui,cli}
                        Level of the analysis that will be performed. Multiple
                        participant level analyses can be run independently
                        (in parallel) using the same output_dir. GUI will open
                        the CPAC gui (currently only works with singularity)
                        and test_config will run through the entire
                        configuration process but will not execute the
                        pipeline.

optional arguments:
  -h, --help            show this help message and exit
  --pipeline_file PIPELINE_FILE
                        Path for the pipeline configuration file to use. Use
                        the format s3://bucket/path/to/pipeline_file to read
                        data directly from an S3 bucket. This may require AWS
                        S3 credentials specified via the --aws_input_creds
                        option.
  --group_file GROUP_FILE
                        Path for the group analysis configuration file to use.
                        Use the format s3://bucket/path/to/pipeline_file to
                        read data directly from an S3 bucket. This may require
                        AWS S3 credentials specified via the --aws_input_creds
                        option. The output directory needs to refer to the
                        output of a preprocessing individual pipeline.
  --data_config_file DATA_CONFIG_FILE
                        Yaml file containing the location of the data that is
                        to be processed. Can be generated from the CPAC gui.
                        This file is not necessary if the data in bids_dir is
                        organized according to the BIDS format. This enables
                        support for legacy data organization and cloud based
                        storage. A bids_dir must still be specified when using
                        this option, but its value will be ignored. Use the
                        format s3://bucket/path/to/data_config_file to read
                        data directly from an S3 bucket. This may require AWS
                        S3 credentials specified via the --aws_input_creds
                        option.
  --preconfig PRECONFIG
                        Name of the pre-configured pipeline to run.
  --pipeline_override PIPELINE_OVERRIDE
                        Override specific options from the pipeline
                        configuration. E.g.: &quot;maximumMemoryPerParticipant: 10&quot;
  --aws_input_creds AWS_INPUT_CREDS
                        Credentials for reading from S3. If not provided and
                        s3 paths are specified in the data config we will try
                        to access the bucket anonymously use the string &quot;env&quot;
                        to indicate that input credentials should read from
                        the environment. (E.g. when using AWS iam roles).
  --aws_output_creds AWS_OUTPUT_CREDS
                        Credentials for writing to S3. If not provided and s3
                        paths are specified in the output directory we will
                        try to access the bucket anonymously use the string
                        &quot;env&quot; to indicate that output credentials should read
                        from the environment. (E.g. when using AWS iam roles).
  --n_cpus N_CPUS       Number of execution resources available for the
                        pipeline.
  --mem_mb MEM_MB       Amount of RAM available to the pipeline in megabytes.
                        Included for compatibility with BIDS-Apps standard,
                        but mem_gb is preferred
  --mem_gb MEM_GB       Amount of RAM available to the pipeline in gigabytes.
                        if this is specified along with mem_mb, this flag will
                        take precedence.
  --save_working_dir [SAVE_WORKING_DIR]
                        Save the contents of the working directory.
  --disable_file_logging
                        Disable file logging, this is useful for clusters that
                        have disabled file locking.
  --participant_label PARTICIPANT_LABEL [PARTICIPANT_LABEL ...]
                        The label of the participant that should be analyzed.
                        The label corresponds to sub-&lt;participant_label&gt; from
                        the BIDS spec (so it does not include &quot;sub-&quot;). If this
                        parameter is not provided all participants should be
                        analyzed. Multiple participants can be specified with
                        a space separated list. To work correctly this should
                        come at the end of the command line.
  --participant_ndx PARTICIPANT_NDX
                        The index of the participant that should be analyzed.
                        This corresponds to the index of the participant in
                        the data config file. This was added to make it easier
                        to accommodate SGE array jobs. Only a single
                        participant will be analyzed. Can be used with
                        participant label, in which case it is the index into
                        the list that follows the participant_label flag. Use
                        the value &quot;-1&quot; to indicate that the participant index
                        should be read from the AWS_BATCH_JOB_ARRAY_INDEX
                        environment variable.
  -v, --version         show program&#39;s version number and exit
  --bids_validator_config BIDS_VALIDATOR_CONFIG
                        JSON file specifying configuration of bids-validator:
                        See https://github.com/bids-standard/bids-validator
                        for more info.
  --skip_bids_validator
                        Skips bids validation.
  --anat_only           run only the anatomical preprocessing
  --tracking_opt-out    Disable usage tracking. Only the number of
                        participants on the analysis is tracked.
  --monitoring          Enable monitoring server on port 8080. You need to
                        bind the port using the Docker flag &quot;-p&quot;.
</pre></div>
</div>
</div>
<div class="section" id="usage-cpac-utils">
<h2>Usage: cpac utils<a class="headerlink" href="#usage-cpac-utils" title="Permalink to this headline">¶</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ cpac utils --help
...
Usage: run.py utils [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  crash
  data_config
  group_config
  pipe_config
  repickle
  test
  tools
  workflows
</pre></div>
</div>
<p>Note that any of the optional arguments above will over-ride any pipeline settings in the default pipeline or in the pipeline configuration file you provide via the <code class="docutils literal notranslate"><span class="pre">--pipeline_file</span></code> parameter.</p>
<p><strong>Further usage notes:</strong></p>
<ul class="simple">
<li>You can run only anatomical preprocessing easily, without modifying your data or pipeline configuration files, by providing the <code class="docutils literal notranslate"><span class="pre">--anat_only</span></code> flag.</li>
<li>As stated, the default behavior is to read data that is organized in the BIDS format. This includes data that is in Amazon AWS S3 by using the format <code class="docutils literal notranslate"><span class="pre">s3://&lt;bucket_name&gt;/&lt;bids_dir&gt;</span></code> for the <code class="docutils literal notranslate"><span class="pre">bids_dir</span></code> command line argument. Outputs can be written to S3 using the same format for the <code class="docutils literal notranslate"><span class="pre">output_dir</span></code>. Credentials for accessing these buckets can be specified on the command line (using <code class="docutils literal notranslate"><span class="pre">--aws_input_creds</span></code> or <code class="docutils literal notranslate"><span class="pre">--aws_output_creds</span></code>).</li>
<li>When the app is run, a data configuration file is written to the working directory. This directory can be specified with <code class="docutils literal notranslate"><span class="pre">--working_dir</span></code> or the directory from which you run <code class="docutils literal notranslate"><span class="pre">cpac</span></code> will be used. This file can be passed into subsequent runs, which avoids the overhead of re-parsing the BIDS input directory on each run (i.e. for cluster or cloud runs). These files can be generated without executing the C-PAC pipeline using the <code class="docutils literal notranslate"><span class="pre">test_run</span></code> command line argument.</li>
<li>The <code class="docutils literal notranslate"><span class="pre">participant_label</span></code> and <code class="docutils literal notranslate"><span class="pre">participant_ndx</span></code> arguments allow the user to specify which of the many datasets should be processed, which is useful when parallelizing the run of multiple participants.</li>
<li>If you want to pass runtime options to your container plaform (Docker or Singularity), you can pass them with <code class="docutils literal notranslate"><span class="pre">-o</span></code> or <code class="docutils literal notranslate"><span class="pre">--container_options</span></code>.</li>
</ul>
<div class="toctree-wrapper compound">
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index">
              <img class="logo" src="_static/cpac_logo_vertical.png" alt="Logo"/>
            </a></p>
<h3><a href="index">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick">1. C-PAC Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="subject_list_config">2. Specify Your Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline_config">3. Select Your Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing">4. Pre-Process Your Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="derivatives">5. Compute Derivatives</a></li>
<li class="toctree-l1"><a class="reference internal" href="running">6. All Run Options</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_analysis">7. Run Group Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="output_dir">8. Check Your Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="help">9. Troubleshoot</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnotes">10. Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix#benchmark-package">Benchmark Package</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index">C-PAC 1.6.2 Beta documentation</a> &#187;</li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, C-PAC Team.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.4.
    </div>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-19224662-10"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-19224662-10');
    </script>

  </body>
</html>